{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMFFBN6tugHQ",
        "outputId": "189875f0-8f68-4082-b7c1-f896e69e3c42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy = tensor(0.9754, device='cuda:0')\n",
            "accuracy = tensor(0.9827, device='cuda:0')\n",
            "accuracy = tensor(0.9842, device='cuda:0')\n",
            "accuracy = tensor(0.9817, device='cuda:0')\n",
            "accuracy = tensor(0.9784, device='cuda:0')\n",
            "accuracy = tensor(0.9810, device='cuda:0')\n",
            "accuracy = tensor(0.9803, device='cuda:0')\n",
            "accuracy = tensor(0.9792, device='cuda:0')\n",
            "accuracy = tensor(0.9821, device='cuda:0')\n",
            "accuracy = tensor(0.9799, device='cuda:0')\n",
            "accuracy = tensor(0.9768, device='cuda:0')\n",
            "accuracy = tensor(0.9834, device='cuda:0')\n",
            "accuracy = tensor(0.9830, device='cuda:0')\n",
            "accuracy = tensor(0.9810, device='cuda:0')\n",
            "accuracy = tensor(0.9764, device='cuda:0')\n",
            "accuracy = tensor(0.9818, device='cuda:0')\n",
            "accuracy = tensor(0.9788, device='cuda:0')\n",
            "accuracy = tensor(0.9798, device='cuda:0')\n",
            "accuracy = tensor(0.9742, device='cuda:0')\n",
            "accuracy = tensor(0.9802, device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# task_a.py is a further dev of nn.py\n",
        "\n",
        "# Load observations from the mnist dataset. The observations are divided into a training set and a test set\n",
        "mnist_train = torchvision.datasets.MNIST('./data', train=True, download=True)\n",
        "x_train = mnist_train.data.reshape(-1, 1, 28, 28).float().to(device)  # torch.functional.nn.conv2d argument must include channels (1)\n",
        "y_train = torch.zeros((mnist_train.targets.shape[0], 10)).to(device)  # Create output tensor\n",
        "y_train[torch.arange(mnist_train.targets.shape[0]), mnist_train.targets] = 1  # Populate output\n",
        "\n",
        "mnist_test = torchvision.datasets.MNIST('./data', train=False, download=True)\n",
        "x_test = mnist_test.data.reshape(-1, 1, 28, 28).float().to(device)  # torch.functional.nn.conv2d argument must include channels (1)\n",
        "y_test = torch.zeros((mnist_test.targets.shape[0], 10)).to(device)  # Create output tensor\n",
        "y_test[torch.arange(mnist_test.targets.shape[0]), mnist_test.targets] = 1  # Populate output\n",
        "\n",
        "# Normalization of inputs\n",
        "mean = x_train.mean()\n",
        "std = x_train.std()\n",
        "x_train = (x_train - mean) / std\n",
        "x_test = (x_test - mean) / std\n",
        "\n",
        "# Divide training data into batches to speed up optimization\n",
        "batches = 600\n",
        "x_train_batches = torch.split(x_train, batches)\n",
        "y_train_batches = torch.split(y_train, batches)\n",
        "\n",
        "\n",
        "class ConvolutionalNeuralNetworkModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(ConvolutionalNeuralNetworkModel, self).__init__()\n",
        "\n",
        "        # Model layers (includes initialized model variables):\n",
        "        self.conv = nn.Conv2d(1, 32, kernel_size=5, padding=2)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, padding=2)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
        "        self.dense0 = nn.Linear(64 * 7 * 7, 1024)\n",
        "        self.dense = nn.Linear(1024 * 1 * 1, 10)\n",
        "\n",
        "    def logits(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.pool2(x)\n",
        "        x = self.dense0(x.reshape(-1, 64 * 7 * 7))\n",
        "        return self.dense(x.reshape(-1, 1024 * 1 * 1))\n",
        "\n",
        "    # Predictor\n",
        "    def f(self, x):\n",
        "        return torch.softmax(self.logits(x), dim=1)\n",
        "\n",
        "    # Cross Entropy loss\n",
        "    def loss(self, x, y):\n",
        "        return nn.functional.cross_entropy(self.logits(x), y.argmax(1))\n",
        "\n",
        "    # Accuracy\n",
        "    def accuracy(self, x, y):\n",
        "        return torch.mean(torch.eq(self.f(x).argmax(1), y.argmax(1)).float())\n",
        "\n",
        "\n",
        "model = ConvolutionalNeuralNetworkModel().to(device)\n",
        "\n",
        "# Optimize: adjust W and b to minimize loss using stochastic gradient descent\n",
        "optimizer = torch.optim.Adam(model.parameters(), 0.001)\n",
        "for epoch in range(20):\n",
        "    for batch in range(len(x_train_batches)):\n",
        "        model.loss(x_train_batches[batch], y_train_batches[batch]).backward()  # Compute loss gradients\n",
        "        optimizer.step()  # Perform optimization by adjusting W and b,\n",
        "        optimizer.zero_grad()  # Clear gradients for next step\n",
        "\n",
        "    print(\"accuracy = %s\" % model.accuracy(x_test, y_test))\n",
        "\n"
      ]
    }
  ]
}